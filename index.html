<!DOCTYPE HTML>
<!--
Read Only by HTML5 UP
html5up.net | @ajlkn
Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->

<html>
    <head>
        <title>ALA 2026</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
        <meta name="google-site-verification" content="aK65vKjdK-pwXkpxs-JBibUAgOiIT_3Kq3S66UUr1N8" />
        <link rel="stylesheet" href="assets/css/main.css" />
        <link rel="icon" type="image/png" href="images/icons/robot.png"/>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-3WQZBEV8XB"></script>
        <script>
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());

          gtag('config', 'G-3WQZBEV8XB');
        </script>
        
    </head>
    <body class="is-preload">
        
        <!-- Header -->
        <section id="header">
            <header>
                <!--<span class="image avatar"><img src="images/avatar.jpg" alt="" /></span>-->
                <h1 id="logo"><a href="#">ALA 2026</a></h1>
                <p style="color:#FFF2D2">Adaptive and Learning Agents Workshop<br />
                at AAMAS, Paphos, Cyprus</p>
            </header>
            <nav id="nav">
                <ul>
                    <li><a href="#news" class="active">News</a></li>
                    <li><a href="#about">About</a></li>
                    <li><a href="#dates">Important Dates</a></li>
                    <li><a href="#submission">Submission Details</a></li>
                    <!--<li><a href="#journal">Journal Special Issue</a></li>-->
                    <!-- <li><a href="#program">Program</a></li> -->
                    <!-- <li><a href="#posters">Poster Sessions</a></li> -->
                    <!-- <li><a href="#accepted">Accepted Papers</a></li> -->
                    <!-- <li><a href="#talks">Invited Talks</a></li> -->
                    <!-- <li><a href="#awards">Awards</a></li> -->
                    <li><a href="#previouseditions">Previous Editions</a></li>
                    <li><a href="#pc">Program Committee</a></li>
                    <li><a href="#organization">Organization</a></li>
                    <!--<li><a href="#sponsor">Sponsorship</a></li>-->
                    <li><a href="#contact">Contact</a></li>
                    
                </ul>
            </nav>
            <footer>
                <ul class="icons">
                    <li><a href="https://www.linkedin.com/groups/4412140/" class="icon fa-linkedin"><span class="label">Linkedin</span></a></li>
                    <li><a href="mailto:ala.workshop.aamas@gmail.com" class="icon fa-envelope"><span class="label">Email</span></a></li>
                </ul>
            </footer>
        </section>
        
        <!-- Wrapper -->
        <div id="wrapper">
            
            <!-- Main -->
            <!-- News -->
            <section id="news">
                <div id="main">
                    <div class="image main" data-position="center">
                        <img src="images/paphos.jpg" alt=""/>
                        <h2 id="banner-header" style="color:#FFF2D2">ALA 2026</h2>
                        <h3 id="banner-description" style="color:#FFF2D2">25 &amp; 26 May 2026, Paphos, Cyprus</h3>
                    </div>
                    <div class="container">
                        <h3>News</h3>
                        <ul>

<!--
                        <li>21 May 2025: Best paper is announced in the <a href="#awards"><em>awards</em></a>.</li>
                        <li>5 May 2025: Camera-ready copies of all papers are viewable in the <a href="#program"><em>program</em></a>.</li>
                        <li>2 May 2025: Poster size should be maximum A0. For details see: <a href="#posters"><em>Poster Sessions</em></a></li>
                        <li>25 Apr 2025: The <a href="#program"><em>program</em></a> for the workshop is now available.</li>
                        <li>10 Apr 2025: The deadline for the camera-ready version of accepted papers has been extended to 1 May 2025.</li>
                        <li>28 Mar 2025: We are excited to announce Sandip Sen as a keynote speaker for ALA 2025.</li>
                        <li>12 Mar 2025: We are excited to announce Eugene Vinitsky as a keynote speaker for ALA 2025.</li>
                        <li>26 Feb 2025: We are excited to announce Roxana Rădulescu as a keynote speaker for ALA 2025.</li>
                        <li>24 Feb 2025: ALA 2025 submission deadline has been further to 1 March 2025 23:59 AOE.</li>
                        <li>30 Jan 2025: ALA 2025 submission deadline has been further to 25 Feb 2025 23:59 AOE.</li>
                        <li>24 Jan 2025: Added the <a href="https://openreview.net/group?id=ifaamas.org/AAMAS/2025/Workshop/ALA" alt="" target="_blank">OpenReview link</a> to the submission details!</li>
                        -->
                            <li>10 Dec 2025: ALA 2026 website goes live!</li>
                        </ul>
                    </div>
                </section>
            <!-- One -->
            <section id="about">
                <div class="container">
                    <header class="major">
                        <h3>ALA 2026 - Workshop at <a href="https://cyprusconferences.org/aamas2026/" target="_blank">AAMAS 2026</a></h3>
                        <p align="justify">Adaptive and Learning Agents (ALA) brings together researchers working on learning, adaptation, and autonomous behaviour in single- and multi-agent systems. The workshop welcomes contributions from across computer science (including reinforcement learning, agent architectures, evolutionary computation, planning, and game theory) as as well as from related fields such as cognitive science, biology, economics, and the social sciences.</p>
                    </header>
                    <!-- <p align="justify">The goal of this workshop is to increase awareness of and interest in adaptive agent research, encourage collaboration and give a representative overview of current research in the area of adaptive and learning agents and multi-agent systems. It aims at bringing together not only scientists from different areas of computer science (e.g. agent architectures, reinforcement learning, evolutionary algorithms) but also from different fields studying similar concepts (e.g. game theory, bio-inspired control, mechanism design).</p> -->
                    <!-- <p align="justify">The workshop will serve as an inclusive forum for the discussion of ongoing or completed work covering both theoretical and practical aspects of adaptive and learning agents and multi-agent systems.</p> -->
                    <p align="justify">ALA aims to foster collaboration, highlight recent advances, and provide a representative overview of current research on adaptive and learning agents. It serves as an inclusive forum for discussing both theoretical foundations and practical applications, spanning topics such as learning and adaptation in dynamic or open-ended environments, coordination and communication among multiple agents, incentive and mechanism design, and the emergence of collective behaviour in complex systems.</p>
                    <!-- <p align="justify">This workshop will focus on all aspects of adaptive and learning agents and multi-agent systems with a particular amphasis on how to modify established learning techniques and/or create new learning paradigms to address the many challenges presented by complex real-world problems. The topics of interest include but are not limited to:</p> -->
                    <p align="justify">The workshop places particular emphasis on emerging learning paradigms and on methods that enable agents to operate reliably in large-scale, uncertain, or evolving environments. We encourage work that extends established techniques or introduces new frameworks to address the challenges of real-world adaptive and multi-agent systems. Topics of interest include, but are not limited to:</p>
                    
                    <ul>
                        <!-- <li>Novel combinations of reinforcement and supervised learning approaches</li> -->
                        <li>Reinforcement learning (single- and multi-agent)</li>
                        <!-- <li>Integrated learning approaches using reasoning modules like negotiation, trust, coordination, etc..</li> -->
                        <!-- <li>Supervised and semi-supervised multi-agent learning</li> -->
                        <li>Representation learning for single- and multi-agent systems</li>
                        <li>Adaptation in dynamic environments</li>
                        <li>Foundation models for adaptive (multi-)agent systems</li>
                        <!-- <li>Deep learning approaches for adaptive single- and multi-agent systems</li> -->
                        <li>Multi-objective optimisation in single- and multi-agent systems</li>
                        <!-- <li>Planning (single- and multi-agent)</li>
                        <li>Reasoning (single- and multi-agent)</li> -->
                        <li>Model-based RL and planning with learned world models (single- and multi-agent)</li>
                        <li>Batch and offline (multi-agent) reinforcement learning</li>
                        <li>Integrating learning with symbolic or game-theoretic reasoning</li>
                        <li>Game theoretical analysis of adaptive multi-agent systems</li>
                        <li>Neurosymbolic and logical reasoning for (multi-agent) decision-making</li>
                        <li>Safety, robustness, and trustworthy (multi-agent) reinforcement learning</li>
                        <!-- <li>Distributed learning</li> -->
                        <li>Decentralized, federated, and communication-aware multi-agent learning</li>
                        <!-- <li>Evolution of agents in complex environments</li> -->
                        <li>Evolutionary and open-ended learning in multi-agent populations</li>
                        <li>Co-evolution of agents in a multi-agent setting</li>
                        <li>Cooperative exploration and learning to cooperate and collaborate</li>
                        <!-- <li>Learning trust and reputation</li> -->
                        <li>Learning and modelling trust, reputation, and social norms in human–AI and multi-agent systems</li>
                        <!-- <li>Communication restrictions and their impact on multi-agent coordination</li> -->
                        <!-- <li>Design of reward structure and fitness measures for coordination</li> -->
                        <!-- <li>Emergent communication, information constraints, and their impact on multi-agent coordination</li> -->
                        <!-- <li>Scaling learning techniques to large systems of learning and adaptive agents</li> -->
                        <li>Emergent behaviour in adaptive multi-agent systems</li>
                        <!-- outdated topic
                        <li>Neuro-control in multi-agent systems</li>
                        -->
                        <li>Multi-agent reinforcement learning and control for cyber-physical systems and robotics</li>
                        <!--
                        <li>Bio-inspired multi-agent systems</li>
                        -->
                        <li>Self-organizing, swarm, and bio-inspired adaptive multi-agent systems</li>
                        <li>Human-in-the-loop learning systems</li>
                        <li>Applications of adaptive and learning agents and multi-agent systems to real world complex systems</li>
                    </ul>
                    
                    <!--<p align="justify">Extended and revised versions of papers presented at the workshop will be eligible for inclusion in a journal special issue (see below).</p>-->
                    <p class="entry-footer"></p>
                </div>
            </section>
            
            <!-- Two -->
            <section id="dates">
                <div class="container">
                    <h3>Important Dates</h3>
                    
                    <ul class="feature-icons">
                        
                        <li class="fa-telegram">Submission Deadline: 4 February 2026
                        <li class="fa-bell">Notification of acceptance: 20 March 2026
                            <li class="fa-file-pdf-o">Camera-ready copies: 15 April 2026
                        </li>
                        <li class="fa-users">Workshop: 25 - 26 May 2026</li>
                    
                    </ul>
                </div>
            </section>
            
            <!-- Three -->
                <section id="submission">
                    <div class="container">
                        <h3>Submission Details</h3>
                        <p align="justify">Papers can be submitted through
                            <!-- update the URL here-->
                            <a href="" alt="" target="_blank">OpenReview</a>.
                        </p>
                        <p align="justify">We invite submission of original work, up to 8 pages in length (excluding references) in the ACM proceedings format (i.e., following the AAMAS formatting instructions). This includes work that has been accepted as a poster/extended abstract at AAMAS 2026. Papers are limited to 8 pages plus references. Additionally, we welcome submission of preliminary results, i.e. work-in-progress, as well as visionary outlook papers that lay out directions for future research in a specific area, both up to 6 pages in length, although shorter papers are very much welcome, and will not be judged differently. Finally, we also accept recently published journal papers in the form of a 2 page abstract.</p>
                        <p align="justify">Furthermore, <strong> for submissions that were rejected or accepted as extended abstracts at AAMAS</strong>, authors need to also append the received reviews and a pdfdiff.</p>
                        <p align="justify">All submissions will be peer-reviewed (double-blind). Accepted work will be allocated time for poster and possibly oral presentation during the workshop. In line with AAMAS, the workshop will be <strong>in person</strong>. </p>
                        <!--Extended versions of original papers presented at the workshop will also be eligible for inclusion in a post-proceedings journal special issue. -->
                        
                        <!-- <p align="justify">When preparing your submission for ALA 2025, please be sure to remove the AAMAS copyright block, citation information and running headers. Please replace the AAMAS copyright block in the main.tex file from the AAMAS template with the following:
                            <pre>
    \setcopyright{none}
    \acmConference[ALA '25]{Proc.\@ of the Adaptive and Learning Agents Workshop (ALA 2025)}{May 19 -- 20, 2025}{Detroit, Michigan, USA, ala-workshop.github.io}{Avalos, Aydeniz, M\"uller, Mohammedalamen (eds.)}
    \copyrightyear{2025}
    \acmYear{2025}
    \acmDOI{}
    \acmPrice{}
    \acmISBN{}
    \settopmatter{printacmref=false}
                            </pre>
                        </p>
                        <p align="justify">For the submission of the camera-ready paper make sure to submit the deanonymized version with the replaced copyright block above.</p> -->
                </div>
            </section>

            
            <!-- Four -->
            <!--
            <section id="journal">
                <div class="container">
                    <h3>Journal Special Issue</h3>
                    
                    <p align="justify">We are delighted to announce that extended versions of all original contributions at ALA 2025 will be eligible for inclusion in a special issue of the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" alt="https://www.springer.com/computer/ai/journal/521" target="_blank">Neural Computing and Applications</a> (Impact Factor 6.0). The deadline for submitting extended papers will be 15 November 2025.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                    
                    <p align="justify">For further information please contact the workshop organizers and Connor Yates.</p>
                    <p class="entry-footer"></p>
                    
                </div>
            </section>
            -->
            
            <!-- Five -->
            <!-- Program: to be updated after paper acceptance
            <section id="program">
                <div class="container">
                    <h3>Program</h3>
                    <p>All times are presented in local Detroit time.</p>
                    <h4>Monday May 19</h4>
                    <table width="100%" >
                    <tr>
                        <td>08:30-9:00</td>
                        <td><b>Welcome &amp; Opening Remarks</b>
                    </tr>
                    <tr>
                        <td>09:00-10:00</td>
                        <td><b>Session I - Chair: A. Alp Aydeniz</b></td>
                        <tr>
                            <td>09:00-10:00</td>
                            <td>Invited Talk: <br/><em>Eugene Vinitsky</em></td>
                    </tr>
                    <tr>
                        <td>10:00-10:45</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>10:45-12:30</td><td><b>Session II - Chair: Raphael Avalos</b></tr>
                    <tr>
                        <td>10:45-11:00</td>
                        <td>Long Talk: Umer Siddique, Peilang Li, Yongcan Cao <br><a href="papers/ALA2025_paper_43.pdf"><em>Learning Fair Pareto-Optimal Policies in Multi-Objective Reinforcement Learning</em></a></td>
                    <tr>
                        <td>11:00-11:15</td>
                        <td>Long Talk: Patrick Benjamin, Alessandro Abate <br><a href="papers/ALA2025_paper_4.pdf"><em>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</em></a></td>
                    </tr>
                    <tr>
                        <td>11:15-11:30</td>
                        <td>Long Talk: Rory Lipkis, Adrian Agogino <br><a href="papers/ALA2025_paper_45.pdf"><em>Failure Analysis of Autonomous Systems with RL-Guided MCMC Sampling</em></a></td>
                    </tr>
                    <tr>
                        <td>11:30-11:45</td>
                        <td>Long Talk: Bhavini Jeloka, Yue Guan, Panagiotis Tsiotras <br><a href="papers/ALA2025_paper_16.pdf"><em>Learning Large-Scale Competitive Team Behaviors with Mean-Field Interactions</em></a></td>
                    </tr>
                    <tr>
                        <td>11:45-12:30</td>
                        <td><b>Short Talks, 5 minutes each in order:</b>
                            <ul>
                                <li>Zeki Doruk Erden, Boi Faltings <br><a href="papers/ALA2025_paper_24.pdf"><em>Agential AI for Integrated Continual Learning, Deliberative Behavior, and Comprehensible Models</em></a></li>
                                <li>Augusto Antônio Fontanive Leal, Mateus Begnini Melchiades, Gabriel de Oliveira Ramos <br><a href="papers/ALA2025_paper_28.pdf"><em>A Flexible Approach to Deliberation Cost in the Option-Critic Architecture</em></a></li>
                                <li>Matteo Ceriscioli, Karthika Mohan <br><a href="papers/ALA2025_paper_5.pdf"><em>Causal Discovery via Adaptive Agents in Multi-Agent and Sequential Decision Tasks</em></a></li>
                                <li>Yoann Poupart, Aurélie Beynier, Nicolas Maudet <br><a href="papers/ALA2025_paper_6.pdf"><em>Perspectives for Direct Interpretability in Multi-Agent Deep Reinforcement Learning</em></a></li>
                                <li>Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio <br><a href="papers/ALA2025_paper_10.pdf"><em>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies</em></a></li>
                                <li>Lukas Schäfer, Logan Jones, Anssi Kanervisto, Yuhan Cao, Tabish Rashid, Raluca Georgescu, David Bignell, Siddhartha Sen, Andrea Treviño Gavito, Sam Devlin <br><a href="papers/ALA2025_paper_14.pdf"><em>Visual Encoders for Imitation Learning in Modern Video Games</em></a></li>
                                <li>Kevin A. Wang, Jerry Xia, Stephen Chung, Amy Greenwald <br><a href="papers/ALA2025_paper_44.pdf"><em>Dynamic Thinker: Optimizing Decision-Time Planning with Costly Compute</em></a></li>
                                <li>Zeki Doruk Erden, Donia Gasmi, Boi Faltings <br><a href="papers/ALA2025_paper_25.pdf"><em>Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-16:00</td><td><b>Session III & Poster Session - Chair: Raphael Avalos</b></td></tr>
                    <tr>
                        <td>14:00-14:15</td>
                        <td>Long Talk: Jingjing Feng, Lucheng Wang, Alona Tenytska, Bei Peng <br><a href="papers/ALA2025_paper_2.pdf"><em>Sample-Efficient Preference-Based Reinforcement Learning Using Diffusion Models</em></a></td>
                    </tr>
                    <tr>
                        <td>14:15-14:30</td>
                        <td>Long Talk: Alicia P. Wolfe, Oliver Diamond, Brigitte Goeler-Slough, Remi Feuerman, Magdalena Kisielinska, Victoria Manfredi <br><a href="papers/ALA2025_paper_40.pdf"><em>Multicopy Reinforcement Learning Agents</em></a></td>
                    </tr>
                    
                    <tr>
                        <td>14:30-15:45</td>
                        <td><em><a href="#posterA"><b>Poster Session A</b></a></em></td>
                        <tr>
                    <tr>
                        <td>15:45-16:30</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>16:30-17:30</td><td><b>Session IV - Chair: Henrik Müller</b></td><tr>   
                    <tr>
                        <td>16:30-17:30</td>
                        <td>Invited Talk: <br/><em>Sandip Sen</em></td>
                    </tr>
                    <tr>
                        <td>~18:00</td>
                        <td><b>Social Gathering</b> Detroiter Bar (<a href="https://maps.app.goo.gl/Qf5cP7bSc22wXw52A">Google Maps</a>)</td>
                    </tr>
                    </table>
                    <h4>Tuesday May 20</h4>
                    <table width="100%" >
                    <tr>
                        <td>09:00-10:00</td>
                        <td><b>Session V - Chair: Raphael Avalos</b></td>
                    <tr>
                        <td>09:00-10:00</td>
                        <td>Invited Talk: <br/><em>Roxana Rădulescu</em></td>
                    </tr>
                    <tr>
                        <td>10:00-10:45</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr><td>10:45-12:30</td><td><b>Session VI - Chair: Gaurav Dixit</b></tr>
                    <tr>
                        <td>10:45-11:00</td>
                        <td>Long Talk: Tao Li, Juan Guevara, Xinhong Xie, Quanyan Zhu <br><a href="papers/ALA2025_paper_15.pdf"><em>Self-Confirming Transformer for Belief-Conditioned Adaptation in Offline Multi-Agent Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>11:00-11:15</td>
                        <td>Long Talk: Willem Röpke, Raphaël Avalos, Roxana Rădulescu, Ann Nowe, Diederik M Roijers, Florent Delgrange <br><a href="papers/ALA2025_paper_39.pdf"><em>Integrating RL and Planning through Optimal Transport World Models</em></a></td>
                    </tr>
                    <tr>
                        <td>11:15-11:30</td>
                        <td>Long Talk: Yen Ru Lai, Fu-Chieh Chang, Pei-Yuan Wu <br><a href="papers/ALA2025_paper_11.pdf"><em>Leveraging Unlabeled Data Sharing through Kernel Function Approximation in Offline Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>11:30-12:30</td>
                        <td><b>Short Talks, 5 minutes each in order:</b>
                            <ul>
                                <li>Narjes Nourzad, Jared Coleman, Zhongyuan Zhao, Bhaskar Krishnamachari, Gunjan Verma, Santiago Segarra <br><a href="papers/ALA2025_paper_17.pdf"><em>Actor-Twin Framework for Task Graph Scheduling</em></a></li>
                                <li>Thibault Roux, Filipo Studzinski Perotto, Gauthier Picard <br><a href="papers/ALA2025_paper_12.pdf"><em>Towards Scalable Collision Avoidance in Dense Airspaces with Deep Multi-Agent Reinforcement Learning</em></a></li>
                                <li>Gabriel Romio, Mateus Begnini Melchiades, Gabriel de Oliveira Ramos <br><a href="papers/ALA2025_paper_7.pdf"><em>Improving Option Learning with Hindsight Experience Replay</em></a></li>
                                <li>Mateus Begnini Melchiades, Gabriel de Oliveira Ramos, Bruno Castro da Silva <br><a href="papers/ALA2025_paper_26.pdf"><em>Dynamic Option Creation in Option-Critic Reinforcement Learning</em></a></li>
                                <li>Florian Grötschla, Joël Mathys, Loïc Holbein, Roger Wattenhofer <br><a href="papers/ALA2025_paper_20.pdf"><em>Reinforcement Learning for Locally Checkable Labeling Problems</em></a></li>
                                <li>Bernhard Hilpert, Muhan Hou, Kim Baraka, Joost Broekens <br><a href="papers/ALA2025_paper_22.pdf"><em>Can You See How I learn? Human Observers' Inferences about Reinforcement Learning Agents' Learning Processes</em></a></li>
                                <li>Andries Rosseau, Paolo Turrini, Marjon Blondeel, Ann Nowe <br><a href="papers/ALA2025_paper_29.pdf"><em>Scaling Marginal Cost Tolling to Address Heterogeneity under Imperfect Information in Routing Games</em></a></li>
                                <li>Dimitris Michailidis, Sennay Ghebreab, Fernando P. Santos <br><a href="papers/ALA2025_paper_13.pdf"><em>Understanding Fairness in Congestion Games with Learning Agents</em></a></li>
                                <li>Everardo Gonzalez, Siddarth Iyer, Kagan Tumer <br><a href="papers/ALA2025_paper_31.pdf"><em>Influence Based Reward Shaping Without a Heuristic</em></a></li>
                                <li>Marc Saideh, Jamont, Laurent Vercouter <br><a href="papers/ALA2025_paper_23.pdf"><em>Adaptive Authentication Factor Selection in the Internet of Things: A Trust-Based Multi-Objective Optimization Approach</em></a></li>
                                <li>Fares Chouaki, Aurélie Beynier, Nicolas Maudet, Paolo Viappiani <br><a href="papers/ALA2025_paper_33.pdf"><em>Fairness in Cooperative Multiagent Multiobjective Reinforcement Learning using the Expected Scalarized Return</em></a></li>
                            </ul>
                        </td>
                    </tr>
                    <tr>
                        <td>12:30-14:00</td>
                        <td><b>Lunch Break</b><br/></td>
                    </tr>
                    <tr><td>14:00-15:45</td><td><b>Session VII & Poster Session - Chair: Raphael Avalos</b></td></tr>
                    
                    <tr>
                        <td>14:00-14:15</td>
                        <td>Long Talk: Arnau Mayoral-Macau, Manel Rodriguez-Soto, Enrico Marchesini, Maite López-Sánchez, Marti Sanchez-Fibla, Alessandro Farinelli, Juan Antonio Rodriguez Aguilar <br><a href="papers/ALA2025_paper_1.pdf"><em>Designing ethical environments using multi-agent reinforcement learning</em></a></td>
                    </tr>
                    <tr>
                        <td>14:15-14:30</td>
                        <td>Long Talk: Daniel Melcer, Stavros Tripakis, Christopher Amato <br><a href="papers/ALA2025_paper_42.pdf"><em>Learned Shields for Multi-Agent Reinforcement Learning</em></a></td>
                    </tr>
                    <tr>
                        <td>14:30-15:45</td>
                        <td><em><a href="#posterB"><b>Poster Session B</b></a></em></td>
                    </tr>
                    <tr>
                        <td>15:45-16:30</td>
                        <td><b>Coffee Break</b><br/></td>
                    </tr>
                    <tr>
                        <td>16:30-17:30</td>
                        <td>Panel Session<br/><em><a href="#"></a></em></td>
                    </tr>
                    <tr>
                        <td>17:30</td>
                        <td><b>Awards & Closing Remarks</b></td>
                    </tr>
                    </table>
                </div>
            </section>


            <section id="posters">
                <div class="container">
                    <h3>Poster Sessions</h3>
                    <p><b>Maximum poster dimensions:</b> A0, which is approximately 46.8 inches tall by 33.1 inches wide (1189mm in height by 841mm in width). Portrait orientation is recommended.</p>
                </div>
                <div id="posterA" class="container">
                    <h4>Poster Session A - Monday May 19 14:30-15:45</h4>
                    <p>All papers presented on day 1.</p>
                </div>
                <div id="posterB" class="container">
                    <h4>Poster Session B - Tuesday May 20 14:30-15:45</h4>
                    <p>All papers presented on day 2.</p>
                </div>
            </section>
            -->

            
        <!-- Accepted Papers; to be modified after paper acceptance 
        <section id="accepted">
            <div class="container">
                <h3>Accepted Papers</h3>
                TBA.
                <p></p>                  
            
                <table style="width:100%">
                    <tr style="text-align:center">
                        <th>Paper #</th>
                        <th>Authors</th>
                        <th>Title</th>
                    </tr>
            <tr><td>1</td><td>Arnau Mayoral-Macau, Manel Rodriguez-Soto, Enrico Marchesini, Maite López-Sánchez, Marti Sanchez-Fibla, Alessandro Farinelli, Juan Antonio Rodriguez Aguilar </td><td>Designing ethical environments using multi-agent reinforcement learning</td></tr>
            <tr><td>2</td><td>Jingjing Feng, Lucheng Wang, Alona Tenytska, Bei Peng </td><td>Sample-Efficient Preference-Based Reinforcement Learning Using Diffusion Models</td></tr>
            <tr><td>4</td><td>Patrick Benjamin, Alessandro Abate </td><td>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</td></tr>
            <tr><td>5</td><td>Matteo Ceriscioli, Karthika Mohan </td><td>Causal Discovery via Adaptive Agents in Multi-Agent and Sequential Decision Tasks</td></tr>
            <tr><td>6</td><td>Yoann Poupart, Aurélie Beynier, Nicolas Maudet </td><td>Perspectives for Direct Interpretability in Multi-Agent Deep Reinforcement Learning</td></tr>
            <tr><td>7</td><td>Gabriel Romio, Mateus Begnini Melchiades, Gabriel de Oliveira Ramos </td><td>Improving Option Learning with Hindsight Experience Replay</td></tr>
            <tr><td>10</td><td>Pedro Sequeira, Vidyasagar Sadhu, Melinda Gervasio </td><td>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies</td></tr>
            <tr><td>11</td><td>Yen Ru Lai, Fu-Chieh Chang, Pei-Yuan Wu </td><td>Leveraging Unlabeled Data Sharing through Kernel Function Approximation in Offline Reinforcement Learning</td></tr>
            <tr><td>12</td><td>Thibault Roux, Filipo Studzinski Perotto, Gauthier Picard </td><td>Towards Scalable Collision Avoidance in Dense Airspaces with Deep Multi-Agent Reinforcement Learning</td></tr>
            <tr><td>13</td><td>Dimitris Michailidis, Sennay Ghebreab, Fernando P. Santos </td><td>Understanding Fairness in Congestion Games with Learning Agents</td></tr>
            <tr><td>14</td><td>Lukas Schäfer, Logan Jones, Anssi Kanervisto, Yuhan Cao, Tabish Rashid, Raluca Georgescu, David Bignell, Siddhartha Sen, Andrea Treviño Gavito, Sam Devlin </td><td>Visual Encoders for Imitation Learning in Modern Video Games</td></tr>
            <tr><td>15</td><td>Tao Li, Juan Guevara, Xinhong Xie, Quanyan Zhu </td><td>Self-Confirming Transformer for Belief-Conditioned Adaptation in Offline Multi-Agent Reinforcement Learning</td></tr>
            <tr><td>16</td><td>Bhavini Jeloka, Yue Guan, Panagiotis Tsiotras </td><td>Learning Large-Scale Competitive Team Behaviors with Mean-Field Interactions</td></tr>
            <tr><td>17</td><td>Narjes Nourzad, Jared Coleman, Zhongyuan Zhao, Bhaskar Krishnamachari, Gunjan Verma, Santiago Segarra </td><td>Actor-Twin Framework for Task Graph Scheduling</td></tr>
            <tr><td>20</td><td>Florian Grötschla, Joël Mathys, Loïc Holbein, Roger Wattenhofer </td><td>Reinforcement Learning for Locally Checkable Labeling Problems</td></tr>
            <tr><td>22</td><td>Bernhard Hilpert, Muhan Hou, Kim Baraka, Joost Broekens </td><td>Can You See How I learn? Human Observers' Inferences about Reinforcement Learning Agents' Learning Processes</td></tr>
            <tr><td>23</td><td>Marc Saideh, Jamont, Laurent Vercouter </td><td>Adaptive Authentication Factor Selection in the Internet of Things: A Trust-Based Multi-Objective Optimization Approach</td></tr>
            <tr><td>24</td><td>Zeki Doruk Erden, Boi Faltings </td><td>Agential AI for Integrated Continual Learning, Deliberative Behavior, and Comprehensible Models</td></tr>
            <tr><td>25</td><td>Zeki Doruk Erden, Donia Gasmi, Boi Faltings </td><td>Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition</td></tr>
            <tr><td>26</td><td>Mateus Begnini Melchiades, Gabriel de Oliveira Ramos, Bruno Castro da Silva </td><td>Dynamic Option Creation in Option-Critic Reinforcement Learning</td></tr>
            <tr><td>28</td><td>Augusto Antônio Fontanive Leal, Mateus Begnini Melchiades, Gabriel de Oliveira Ramos </td><td>A Flexible Approach to Deliberation Cost in the Option-Critic Architecture</td></tr>
            <tr><td>29</td><td>Andries Rosseau, Paolo Turrini, Marjon Blondeel, Ann Nowe </td><td>Scaling Marginal Cost Tolling to Address Heterogeneity under Imperfect Information in Routing Games</td></tr>
            <tr><td>31</td><td>Everardo Gonzalez, Siddarth Iyer, Kagan Tumer </td><td>Influence Based Reward Shaping Without a Heuristic</td></tr>
            <tr><td>33</td><td>Fares Chouaki, Aurélie Beynier, Nicolas Maudet, Paolo Viappiani </td><td>Fairness in Cooperative Multiagent Multiobjective Reinforcement Learning using the Expected Scalarized Return</td></tr>
            <tr><td>39</td><td>Willem Röpke, Raphaël Avalos, Roxana Rădulescu, Ann Nowe, Diederik M Roijers, Florent Delgrange </td><td>Integrating RL and Planning through Optimal Transport World Models</td></tr>
            <tr><td>40</td><td>Alicia P. Wolfe, Oliver Diamond, Brigitte Goeler-Slough, Remi Feuerman, Magdalena Kisielinska, Victoria Manfredi </td><td>Multicopy Reinforcement Learning Agents</td></tr>
            <tr><td>42</td><td>Daniel Melcer, Stavros Tripakis, Christopher Amato </td><td>Learned Shields for Multi-Agent Reinforcement Learning</td></tr>
            <tr><td>43</td><td>Umer Siddique, Peilang Li, Yongcan Cao </td><td>Learning Fair Pareto-Optimal Policies in Multi-Objective Reinforcement Learning</td></tr>
            <tr><td>44</td><td>Kevin A. Wang, Jerry Xia, Stephen Chung, Amy Greenwald </td><td>Dynamic Thinker: Optimizing Decision-Time Planning with Costly Compute</td></tr>
            <tr><td>45</td><td>Rory Lipkis, Adrian Agogino </td><td>Failure Analysis of Autonomous Systems with RL-Guided MCMC Sampling</td></tr>
        </table>
    </div>
</section>
         -->



<!-- Six -->

<!--
<section id="talks">
    <div class="container">
        <h3>Invited Talks</h3>
        <h4 id='talks1'>Roxana Rădulescu</h4>
        <div style="width:100%;">
                <div style="width:35%; float:left;"><img src="images/roxanaradulescu.jpg" width="90%" image-orientation="from-image"></div>
                <div style="width:65%; float:right;">
                    
                <div style="width:100%; float:right;">
                    <p><b>Affiliation:</b> Utrecht University</p>
                    <p><b>Website:</b> <a href="https://www.uu.nl/staff/RTRadulescu" target="_blank">https://www.uu.nl/staff/RTRadulescu</a></p>
                </div>
            </div>
            <p align="justify" class="title"><b>Title:</b> Dissecting multi-objective learning agents
            </p>
            <p align="justify" class="abstract"><b>Abstract:</b> Most real-world problems involve multiple, potentially conflicting objectives; for example, safety versus fuel efficiency versus speed in autonomous driving, or treatment effectiveness versus side effects in medical treatment planning. Tackling such problems using reinforcement learning (RL) methods either requires an a-priori scalarisation of the reward signal, or involves applying multi-objective RL. In this talk I compare these approaches, by taking a deep dive into multi-objective RL in single and multi-agent settings. The goal is to highlight practical considerations, theoretical results, and additional challenges and benefits, as well as to delineate how and when it is appropriate to use multi-objective RL.
            </p>
            <p align="justify" class="bio"><b>Bio:</b> Roxana Rădulescu is Assistant Professor in AI and Data Science, at the Department of Information and Computing Sciences, at Utrecht University. Before, she was a FWO Postdoctoral fellow at the Artificial Intelligence Lab, Vrije Universiteit Brussel, Belgium. Her research is focussed on the development of multi-agent decision making systems where each agent is driven by different objectives and goals, under the paradigm of multi-objective multi-agent reinforcement learning.
            </p>
            <p class="entry-footer"></p>

        <h4 id='talks2'>Eugene Vinitsky</h4>
            <div style="width:100%;">
                    <div style="width:35%; float:left;"><img src="images/eugenevinitsky.jpg" width="90%" image-orientation="from-image"></div>
                    <div style="width:65%; float:right;">
                        
                    <div style="width:100%; float:right;">
                        <p><b>Affiliation:</b> New York University</p>
                        <p><b>Website:</b> <a href="https://engineering.nyu.edu/faculty/eugene-vinitsky" target="_blank">https://engineering.nyu.edu/faculty/eugene-vinitsky</a></p>
                    </div>
                </div>
                <p align="justify" class="title"><b>Title:</b> Reevaluating Policy Gradient Methods for Imperfect Information Games
                </p>
                <p align="justify" class="abstract"><b>Abstract:</b> In the past decade, motivated by the putative failure of naive self-play deep reinforcement learning (DRL) in adversarial imperfect-information games, researchers have developed numerous DRL algorithms based on fictitious play (FP), double oracle (DO), and counterfactual regret minimization (CFR). In light of recent results of the magnetic mirror descent algorithm, we hypothesize that simpler generic policy gradient methods like PPO are competitive with or superior to these FP, DO, and CFR-based DRL approaches. To facilitate the resolution of this hypothesis, we implement and release the first broadly accessible exact exploitability computations for four large games. Using these games, we conduct the largest-ever exploitability comparison of DRL algorithms for imperfect-information games. Over 5600 training runs, FP, DO, and CFR-based approaches fail to outperform generic policy gradient methods.
                </p>
                <p align="justify" class="bio"><b>Bio:</b> Eugene Vinitsky is a Professor of Civil and Urban Engineering at NYU and a member of the C2SMARTER consortium. His primary research interest is figuring out how to make developing multi-agent controllers, planners, and intelligence as easy as possible by developing new learning algorithms, software, and tools. He looks for applications of these techniques in civil engineering problems and autonomy. He received his PhD in controls engineering from UC Berkeley. 
                </p>
                <p class="entry-footer"></p>
            
        <h4 id='talks3'>Sandip Sen</h4>
            <div style="width:100%;">
                    <div style="width:35%; float:left;"><img src="images/sandipsen.jpg" width="90%" image-orientation="from-image"></div>
                    <div style="width:65%; float:right;">
                        
                    <div style="width:100%; float:right;">
                        <p><b>Affiliation:</b> University of Tulsa</p>
                        <p><b>Website:</b> <a href="https://utulsa.edu/people/sandip-sen/" target="_blank">https://utulsa.edu/people/sandip-sen/</a></p>
                    </div>
                </div>
                <p align="justify" class="title"><b>Title:</b> Adaptive Agents, Emergent Societies
                </p>
                <p align="justify" class="abstract"><b>Abstract:</b> The ALA platform provides a forum for discussion and dissemination of a range of agent learning techniques and adaptive behaviors.  Whereas powerful and effective single and multiagent learning approaches provide opportunities for novel applications of agent technology, we are additionally interested in emergent properties in societies of agents utilizing simpler adaptive behaviors.  In this talk, we present highlights from our research efforts to understand population-wide effects of various adaptive schemes that utilize tag-based interactions, partner selection learning, agent mobility, interaction topology, observational and memory constraints, etc.  The types of emergent phenomena we will discuss include development of social norms in simultaneous and sequential play, cooperation emergence in n-person social dilemmas, and population tipping points.  We will also briefly comment on our relevant research efforts on LLM-based adaptive agents.
                </p>
                <p align="justify" class="bio"><b>Bio:</b> Sandip Sen is a professor in the Tandy School of Computer Science with primary research interests in artificial intelligence, intelligent agents, machine learning, and evolutionary computation. He completed his Ph.D. on intelligent, distributed scheduling from the University of Michigan in December, 1993. He has authored approximately 300 papers in workshops, conferences, and journals in several areas of artificial intelligence. 
                </p>
            
                </div>
            </section>
            -->

            <!-- Six -->
            
            
                <!--   
                <section id="awards">
                    <div class="container">
                        <h3>Awards</h3>
                        <h4 id='bestpaperaward'>Best Paper Award</h4>
            
                        <p>We are pleased to announce the best paper of ALA 2025 is "Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation", by Patrick Benjamin and Alessandro Abate!</p>
                        
                        <h4 id='runnerup'>Runner Up Best Paper Award</h4>
            
                        <p>We are pleased to announce the runner up for the best paper of ALA 2025 is "Self-Confirming Transformer for Belief-Conditioned Adaptation in Offline Multi-Agent Reinforcement Learning", by Tao Li, Juan Guevara, Xinhong Xie, and Quanyan Zhu!</p>
                </div> 
            </section>
            -->
            
            
            <section id="previouseditions">
                <div class="container">
                    <h3>Previous Editions</h3>
                    
                    <p align="justify">This workshop is a continuation of the long running AAMAS series of workshops on adaptive agents, now in its sixteenth year. Previous editions of this workshop may be found at the following urls:</p>
                    <ul>
                        <li><a href="https://ala2024.github.io/" target="_blank">ALA-24</a></li>
                        <li><a href="https://alaworkshop2023.github.io/" target="_blank">ALA-23</a></li>
                        <li><a href="https://ala2022.github.io/" target="_blank">ALA-22</a></li>
                        <li><a href="http://ala2021.vub.ac.be" target="_blank">ALA-21</a></li>
                        <li><a href="http://ala2020.vub.ac.be" target="_blank">ALA-20</a></li>
                        <li><a href="http://ala2019.vub.ac.be" target="_blank">ALA-19</a></li>
                        <li><a href="http://ala2018.it.nuigalway.ie" target="_blank">ALA-18</a></li>
                        <li><a href="http://ala2017.it.nuigalway.ie/" target="_blank">ALA-17</a></li>
                        <li><a href="http://ala2016.csc.liv.ac.uk/" target="_blank">ALA-16</a></li>
                        <li><a href="http://ala2015.csc.liv.ac.uk/" target="_blank">ALA-15</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2014/" target="_blank">ALA-14</a></li>
                        <li><a href="http://swarmlab.unimaas.nl/ala2013/" target="_blank">ALA-13</a></li>
                        <li><a href="http://ai.vub.ac.be/ALA2012/" target="_blank">ALA-12</a></li>
                        <li><a href="http://como.vub.ac.be/ALA2011/" target="_blank">ALA-11</a></li>
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekudenko/ala10/" target="_blank">ALA-10</a></li>
                        <li><a href="http://teamcore.usc.edu/taylorm/ALA09/" target="_blank">ALA-09</a></li>
                        <li><a href="http://ki.informatik.uni-wuerzburg.de/%7Ekluegl/ALAMAS.ALAg/" target="_blank">ALAMAS+ALAg-08</a></li>
                        <li><a href="http://web.engr.oregonstate.edu/%7Ektumer/conferences/alag07.html" target="_blank">ALAg-07</a></li>
                        <!--  <li><a href="http://www.cs.unimaas.nl/alamas/">ALAMAS-07</a></li> -->
                        <li><a href="http://www-users.cs.york.ac.uk/%7Ekazakov/aamas/">Earlier editions</a> </li>
                    </ul>
                </div>
            </section>
            
            <!-- Seven -->
            <section id="pc">
                <div class="container">
                    <h3>Program Committee</h3>
                    TBA.      
                    
                    <!-- <ul>
                        <li>Erman Acar, University of Amsterdam</li>
                        <li>Adrian Agogino, University of Texas, Austin</li>
                        <li>Lucas N. Alegre, Institute of Informatics - Federal University of Rio Grande do Sul</li>
                        <li>Nitay Alon, Hebrew University of Jerusalem</li>
                        <li>Philipp Altmann, LMU Munich</li>
                        <li>Hicham Azmani, Vrije Universiteit Brussel</li>
                        <li>Jérôme Botoko Ekila, Vrije Universiteit Brussel</li>
                        <li>Jacob Brue, University of Tulsa</li>
                        <li>Mustafa Mert Çelikok, Delft University of Technology</li>
                        <li>Fu-Chieh Chang, National Taiwan University</li>
                        <li>Alexandra Cimpean, Vrije Universiteit Brussel</li>
                        <li>Kyle Crandall, US Naval Research Lab</li>
                        <li>Vinicius Renan de Carvalho, Universidade de São Paulo</li>
                        <li>Gabriel de Oliveira Ramos, Universidade Vale do Rio dos Sinos</li>
                        <li>Florent Delgrange, Vrije Universiteit Brussel</li>
                        <li>Gaurav Dixit, Oregon State University</li>
                        <li>Elias Fernández Domingos, Vrije Universiteit Brussel</li>
                        <li>Simone Drago, Polytechnic Institute of Milan</li>
                        <li>Flint Xiaofeng Fan, ETHZ - ETH Zurich</li>
                        <li>Florian Felten, ETHZ - ETH Zurich</li>
                        <li>Rolando Fernandez, University of Texas at Austin</li>
                        <li>Timothy Flavin, University of Tulsa</li>
                        <li>Julian Garcia, Monash University</li>
                        <li>Everardo Gonzalez, Oregon State University</li>
                        <li>Davide Grossi, University of Groningen</li>
                        <li>Brent Harrison, University of Kentucky</li>
                        <li>Fredrik Heintz, Linköping University</li>
                        <li>Bernhard Hilpert, Leiden University</li>
                        <li>Athirai Aravazhi Irissappane, Amazon</li>
                        <li>Whiyoung Jung, LG AI Research</li>
                        <li>Michael Kaisers, Google</li>
                        <li>Thommen George Karimpanal, Deakin University</li>
                        <li>Sammie Katt, Aalto University</li>
                        <li>Guangliang Li, Ocean University of China</li>
                        <li>Woohyung Lim, LG AI Research</li>
                        <li>Robert Loftin, University of Sheffield</li>
                        <li>Junlin Lu, National University of Ireland, Galway</li>
                        <li>Joël Mathys, ETHZ - ETH Zurich</li>
                        <li>David Milec, Czech Technical Univeresity in Prague, Czech Technical University of Prague</li>
                        <li>Nicole Orzan, University of Groningen</li>
                        <li>Bei Peng, University of Liverpool</li>
                        <li>Ram Rachum, Tufts University</li>
                        <li>Roxana Rădulescu, Utrecht University (ICS), Utrecht University</li>
                        <li>Carrie Rebhuhn, The MITRE Corporation</li>
                        <li>Mathieu Reymond, Mila - Quebec Artificial Intelligence Institute</li>
                        <li>Juan Antonio Rodriguez Aguilar, Spanish National Research Council</li>
                        <li>Manel Rodriguez-Soto, Artificial Intelligence Research Institute, Spanish National Research Council</li>
                        <li>Diederik Roijers, University of Amsterdam</li>
                        <li>Willem Röpke, Vrije Universiteit Brussel</li>
                        <li>Andries Rosseau, Vrije Universiteit Brussel</li>
                        <li>Vidyasagar Sadhu, SRI International</li>
                        <li>Fernando P. Santos, University of Amsterdam</li>
                        <li>Lukas Schäfer, Microsoft</li>
                        <li>Sandip Sen, University of Tulsa</li>
                        <li>Pedro Sequeira, SRI International</li>
                        <li>William Tomlinson, University of California, Irvine</li>
                        <li>Paolo Turrini, University of Warwick</li>
                        <li>Pascal R. Van der Vaart, Delft University of Technology</li>
                        <li>Garrett Warnell, University of Texas, Austin</li>
                        <li>Connor Yates, Oregon State University</li>
                        <li>Neil Yorke-Smith, Delft University of Technology</li>

                    </ul>
                -->
                </div>
            </section>
            

            
                <!-- eight -->
                <section id="organization">
                    <div class="container">
                        <h3>Organization</h3>
                        This year's workshop is organised by:
                        <ul>
                            <li>A. Alp Aydeniz (Oregon State University, US) </li>
                            <li><a href="https://montaserfath.github.io/" target="_blank">Montaser Mohammedalamen</a> (University of Alberta, CA)</li>
                            <li>Xue Yang University of Galway, Ireland </li>
                            <li><a href="https://delgrange.me" target="_blank">Florent Delgrange</a> (Vrije Universiteit Brussel, BE) </li>
                        </ul>
                    
                    Senior Steering Committee Members:
                    <ul>
                        <li>Enda Howley (University of Galway, IE)</li>
                        <li>Daniel Kudenko (Leibniz University Hannover, DE)</li>
                        <li>Patrick Mannion (University of Galway, IE)</li>
                        <li>Ann Now&eacute; (Vrije Universiteit Brussel, BE)</li>
                        <li>Sandip Sen (University of Tulsa, US)</li>
                        <li>Peter Stone (University of Texas at Austin, US)</li>
                        <li>Matthew Taylor (University of Alberta, CA)</li>
                        <li>Kagan Tumer (Oregon State University, US)</li>
                        <li>Karl Tuyls (University of Liverpool, UK)</li>
                    </ul>
                </div>
            </section>
            
            
            
            <!--
            <section id="sponsor">
                <div class="container">
                    <h3>Sponsorship</h3>
                    <p align="justify">The ALA 2022 Best Paper Award is kindly sponsored by the Springer journal <a href="https://www.springer.com/computer/ai/journal/521" target="_blank"> Neural Computing and Applications</a>.</p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/nca.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>

            <section id="ai_ethics">
                <div class="container">
                    <h3>Trustworthy Adaptive and Learning Agents</h3>
                    <p align="justify">Authors and attendees of ALA 2022 who are interested in trustworthiness in agent-based systems are invited to submit their work to a topical collection (TC) on Trustworthy Adaptive and Learning Agents (TALA).
                    This TC solicits original research articles, reviews/surveys, and opinion pieces/commentaries relating to trustworthiness in agent-based systems, including those that employ learning and/or adaptation.
                    The TALA TC has an open call for papers; it is not necessary to submit preliminary work to the ALA workshop in order to have your manuscript considered for publication in this TC.</p>
                    <p align="justify"><a href="https://www.springer.com/journal/43681/updates/19318686" target="_blank"> AI and Ethics</a></p>
                    <a href="https://www.springer.com/computer/ai/journal/521" target='_blank'><img src='images/ai_ethics.jpg' height='200px' alt='NCA' /></a>
                </div>
            </section>
            -->
            
            <!-- ten -->
            <section id="contact">
                <div class="container">
                    <h3>Contact</h3>
                    <p align="justify">If you have any questions about the ALA workshop, please contact the organizers at: <br/>
                    ala.workshop.aamas AT gmail.com
                    </p>
                    <p> For more general news, discussion, collaboration and networking opportunities with others interested in Adaptive Learning Agents then please join our Linkedin Group
                    <a class="fa" href="https://www.linkedin.com/groups/4412140/" >
                        <i class="fa fa-linkedin"></i>
                    </a> </p>
                </div>
            </section>
        
        <!-- Footer -->
        <section id="footer">
            <div class="container">
                <ul class="copyright">
                    <li>&copy; Adaptive Learning Agents Workshop 2025. All rights reserved.</li>
                    <li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
                    <li>Icons made by <a href="https://www.flaticon.com/authors/freepik" title="Freepik">Freepik</a> from <a href="https://www.flaticon.com/" title="Flaticon">www.flaticon.com</a> are licensed by <a href="http://creativecommons.org/licenses/by/3.0/" title="Creative Commons BY 3.0" target="_blank">CC 3.0 BY</a></li>
                    <!-- <li>Header image by <a href="https://commons.wikimedia.org/wiki/File:Detroit_Skyline_(123143197).jpeg">Michael Tighe</a>, licensed under <a href="https://creativecommons.org/licenses/by-sa/4.0" title="Creative Commons BY-SA 4.0" target="_blank">CC BY-SA 4.0</a>, via Wikimedia Commons</li> -->
                </ul>
            </div>
        </section>
        
        </div>
        
        <!-- Scripts -->
        <script src="assets/js/jquery.min.js"></script>
        <script src="assets/js/jquery.scrollex.min.js"></script>
        <script src="assets/js/jquery.scrolly.min.js"></script>
        <script src="assets/js/browser.min.js"></script>
        <script src="assets/js/breakpoints.min.js"></script>
        <script src="assets/js/util.js"></script>
        <script src="assets/js/main.js"></script>
        
    </body>
</html>
